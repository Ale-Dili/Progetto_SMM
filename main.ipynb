{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from normalizer import Normalizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom = fetch_ucirepo(id=848) \n",
    "  \n",
    "attributes_type = mushroom.variables.type\n",
    "# data (as pandas dataframes) \n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.0027428103571794085\n",
      "Accuracy: 0.9956607172097592\n",
      "Precision: 0.9966789667896679\n",
      "Recall: 0.9935626264484091\n",
      "F1-score: 0.9951183568204844\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import decision_tree\n",
    "importlib.reload(decision_tree)  # Ricarica il modulo\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=88, shuffle=True)\n",
    "\n",
    "\n",
    "normalizer = Normalizer(n_bins=4, normalization='minmax')\n",
    "\n",
    "#X_train = normalizer.normalize(X_train)\n",
    "y_train = normalizer._fix_label(y_train)\n",
    "\n",
    "\n",
    "#X = normalizer.normalize(X)\n",
    "#y = normalizer.normalize(y)\n",
    "\n",
    "#y_train = y_train.to_numpy().flatten()\n",
    "\n",
    "# Decision tree classifier\n",
    "dt = decision_tree.Decision_tree(splitting_criteria = 'gini', max_depth = 30, min_samples_split=20, min_impurity_decrease = 0.001)\n",
    "\n",
    "training_error = dt.fit(X_train, y_train)\n",
    "print(f'training error: {training_error}')\n",
    "\n",
    "#----------PREDICTION\n",
    "#X_test=normalizer.normalize(X_test)\n",
    "y_test = normalizer._fix_label(y_test)\n",
    "prediction = dt.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "precision = precision_score(y_test, prediction, average='binary')\n",
    "recall = recall_score(y_test, prediction, average='binary')\n",
    "f1 = f1_score(y_test, prediction, average='binary')\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Dataset loaded --\n",
      "training error (1/5): 0.0063453075427284825\n",
      "training error (2/5): 0.008044212465459012\n",
      "training error (3/5): 0.008862961825811073\n",
      "training error (4/5): 0.007389212977177362\n",
      "training error (5/5): 0.00921074177173735\n",
      "Stratified K-Fold Cross-Validation Accuracies: [0.9939413787457017, 0.9917308007204847, 0.9895202226952677, 0.9917308007204847, 0.9896012445754524]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import decision_tree\n",
    "importlib.reload(decision_tree)  # Ricarica il modulo\n",
    "from sklearn.model_selection import (train_test_split, KFold, StratifiedKFold, LeaveOneOut)\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "from normalizer import Normalizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "##-------------Load dataset\n",
    "mushroom = fetch_ucirepo(id=848) \n",
    "  \n",
    "attributes_type = mushroom.variables.type\n",
    "# data (as pandas dataframes) \n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets \n",
    "\n",
    "print('-- Dataset loaded --')\n",
    "##-------------\n",
    "\n",
    "\n",
    "normalizer = Normalizer(n_bins=4, normalization='minmax')\n",
    "\n",
    "model = decision_tree.Decision_tree(splitting_criteria = 'gini', max_depth = 20, min_samples_split=20, min_impurity_decrease = 0.001)\n",
    "\n",
    "N_SPLIT = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=42)\n",
    "skf_accuracies=[]\n",
    "count = 1\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train = X.loc[train_index]\n",
    "    y_train = normalizer._fix_label(y.loc[train_index])\n",
    "    X_test = X.loc[test_index]\n",
    "    y_test = normalizer._fix_label(y.loc[test_index])\n",
    "    training_error = model.fit(X_train,y_train)\n",
    "    print(f'training error ({count}/{N_SPLIT}): {training_error}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    skf_accuracies.append(accuracy)\n",
    "    count +=1\n",
    "\n",
    "print(f\"Stratified K-Fold Cross-Validation Accuracies: {skf_accuracies}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Dataset loaded --\n",
      "training error (1/10): 0.010134274589716531\n",
      "training error (2/10): 0.008988028092136386\n",
      "training error (3/10): 0.008824278592482079\n",
      "training error (4/10): 0.009752192423856483\n",
      "training error (5/10): 0.013718569193260798\n",
      "training error (6/10): 0.013554819693606493\n",
      "training error (7/10): 0.00967941486845457\n",
      "training error (8/10): 0.006950256540882792\n",
      "training error (9/10): 0.007132200429387577\n",
      "training error (10/10): 0.008423848770991393\n",
      "Stratified K-Fold Cross-Validation Accuracies: [0.9893564761748813, 0.9909939413787457, 0.9906664483379728, 0.9888652366137219, 0.985917799246766, 0.9857540527263796, 0.9890289831341084, 0.9927951531029966, 0.992958899623383, 0.9916475597772683]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import decision_tree\n",
    "importlib.reload(decision_tree)  # Ricarica il modulo\n",
    "from sklearn.model_selection import (train_test_split, KFold, StratifiedKFold, KFold,LeaveOneOut)\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "from normalizer import Normalizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "##-------------Load dataset\n",
    "mushroom = fetch_ucirepo(id=848) \n",
    "  \n",
    "attributes_type = mushroom.variables.type\n",
    "# data (as pandas dataframes) \n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets \n",
    "\n",
    "print('-- Dataset loaded --')\n",
    "##-------------\n",
    "\n",
    "\n",
    "normalizer = Normalizer(n_bins=4, normalization='minmax')\n",
    "\n",
    "\n",
    "\n",
    "model = decision_tree.Decision_tree(splitting_criteria = 'gini', max_depth = 20, min_samples_split=20, min_impurity_decrease = 0.001)\n",
    "\n",
    "N_SPLIT = 10\n",
    "\n",
    "kf = KFold(n_splits=N_SPLIT, shuffle=True, random_state=42)\n",
    "kf_accuracies=[]\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train = X.loc[train_index]\n",
    "    y_train = normalizer._fix_label(y.loc[train_index])\n",
    "    X_test = X.loc[test_index]\n",
    "    y_test = normalizer._fix_label(y.loc[test_index])\n",
    "    training_error = model.fit(X_train,y_train)\n",
    "    print(f'training error ({count}/{N_SPLIT}): {training_error}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    kf_accuracies.append(accuracy)\n",
    "    count +=1\n",
    "\n",
    "print(f\"Stratified K-Fold Cross-Validation Accuracies: {kf_accuracies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Dataset loaded --\n",
      "Train error: 0.16516221471701975 -> max_dept= 10 | min_samp = 10\n",
      "Train error: 0.16516221471701975 -> max_dept= 10 | min_samp = 20\n",
      "Train error: 0.16518268345102854 -> max_dept= 10 | min_samp = 30\n",
      "Train error: 0.05929792242349811 -> max_dept= 15 | min_samp = 10\n",
      "Train error: 0.05929792242349811 -> max_dept= 15 | min_samp = 20\n",
      "Train error: 0.05946167229556852 -> max_dept= 15 | min_samp = 30\n",
      "Train error: 0.0068774946269573225 -> max_dept= 20 | min_samp = 10\n",
      "Train error: 0.0068774946269573225 -> max_dept= 20 | min_samp = 20\n",
      "Train error: 0.007041244499027735 -> max_dept= 20 | min_samp = 30\n",
      "[0.8357622400523989, 0.8357622400523989, 0.8357622400523989, 0.9355657442279351, 0.9355657442279351, 0.9354019977075487, 0.9904208285573931, 0.9904208285573931, 0.9902570820370067]\n",
      "20 10\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import decision_tree\n",
    "importlib.reload(decision_tree)  # Ricarica il modulo\n",
    "from sklearn.model_selection import (train_test_split, KFold, StratifiedKFold, KFold,LeaveOneOut)\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "from normalizer import Normalizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "##-------------Load dataset\n",
    "mushroom = fetch_ucirepo(id=848) \n",
    "  \n",
    "attributes_type = mushroom.variables.type\n",
    "# data (as pandas dataframes) \n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets \n",
    "\n",
    "print('-- Dataset loaded --')\n",
    "##-------------\n",
    "param_grid = {\n",
    "    'max_depth': [10, 15, 20], \n",
    "    'min_samples_split': [10, 20, 30]\n",
    "}\n",
    "\n",
    "best_max_depth = 10\n",
    "best_min_samples_split = 10\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=88, shuffle=True)\n",
    "normalizer = Normalizer(n_bins=4, normalization='minmax')\n",
    "y_train = normalizer._fix_label(y_train)\n",
    "y_test = normalizer._fix_label(y_test)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for max_depth in param_grid['max_depth']:\n",
    "    for min_samples_split in param_grid['min_samples_split']:\n",
    "        model = decision_tree.Decision_tree(splitting_criteria = 'gini', max_depth = max_depth, min_samples_split=min_samples_split, min_impurity_decrease = 0.001)\n",
    "        \n",
    "        t_e = model.fit(X_train,y_train)\n",
    "        print(f'Train error: {t_e} -> max_dept= {max_depth} | min_samp = {min_samples_split}')\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if len(accuracies) == 0 or accuracy > max(accuracies) :\n",
    "            best_max_depth = max_depth\n",
    "            best_min_samples_split = min_samples_split\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "print(accuracies)\n",
    "print(best_max_depth, best_min_samples_split)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Dataset loaded --\n",
      "-- TRAINING ::: max_dept= 20 | min_samp = 10 | criterion = gini | min_impurity = 0.001 ::: --\n",
      "    (1/5): training error: 0.001432811380616109\n",
      "     (1/5): accuracy: 0.4543147208121827\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[test_index]\n\u001b[1;32m     58\u001b[0m y_test \u001b[38;5;241m=\u001b[39m normalizer\u001b[38;5;241m.\u001b[39m_fix_label(y\u001b[38;5;241m.\u001b[39mloc[test_index])\n\u001b[0;32m---> 59\u001b[0m training_error \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_FOLDS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): training error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Documents/Universita/Statistical_Method/progetto/decision_tree.py:38\u001b[0m, in \u001b[0;36mDecision_tree.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmistakes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_thresholds(X)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m t_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_training_error(X)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t_e\n",
      "File \u001b[0;32m~/Documents/Universita/Statistical_Method/progetto/decision_tree.py:107\u001b[0m, in \u001b[0;36mDecision_tree._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    103\u001b[0m X_column \u001b[38;5;241m=\u001b[39m X[best_feature]\n\u001b[1;32m    105\u001b[0m left_idxs, right_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(X_column, best_threshold)\n\u001b[0;32m--> 107\u001b[0m left_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_idxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_idxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m right_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grow_tree(X\u001b[38;5;241m.\u001b[39mloc[right_idxs], y\u001b[38;5;241m.\u001b[39mloc[right_idxs], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Node(feature\u001b[38;5;241m=\u001b[39mbest_feature, threshold\u001b[38;5;241m=\u001b[39mbest_threshold, left\u001b[38;5;241m=\u001b[39mleft_child, right\u001b[38;5;241m=\u001b[39mright_child)\n",
      "File \u001b[0;32m~/Documents/Universita/Statistical_Method/progetto/decision_tree.py:108\u001b[0m, in \u001b[0;36mDecision_tree._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    105\u001b[0m left_idxs, right_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(X_column, best_threshold)\n\u001b[1;32m    107\u001b[0m left_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grow_tree(X\u001b[38;5;241m.\u001b[39mloc[left_idxs], y\u001b[38;5;241m.\u001b[39mloc[left_idxs], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m right_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_idxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_idxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Node(feature\u001b[38;5;241m=\u001b[39mbest_feature, threshold\u001b[38;5;241m=\u001b[39mbest_threshold, left\u001b[38;5;241m=\u001b[39mleft_child, right\u001b[38;5;241m=\u001b[39mright_child)\n",
      "File \u001b[0;32m~/Documents/Universita/Statistical_Method/progetto/decision_tree.py:96\u001b[0m, in \u001b[0;36mDecision_tree._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmistakes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39mvalue_counts()[leaf_value]\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Node(value\u001b[38;5;241m=\u001b[39mleaf_value)\n\u001b[0;32m---> 96\u001b[0m best_feature, best_threshold, best_gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_feature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m best_gain \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease:\n\u001b[1;32m     99\u001b[0m     leaf_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_most_common_label(y)\n",
      "File \u001b[0;32m~/Documents/Universita/Statistical_Method/progetto/decision_tree.py:124\u001b[0m, in \u001b[0;36mDecision_tree._best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    122\u001b[0m continuous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_continuous(X_column)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresholds[colname]:\n\u001b[0;32m--> 124\u001b[0m     gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_information_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gain \u001b[38;5;241m>\u001b[39m best_gain:\n\u001b[1;32m    126\u001b[0m         best_gain \u001b[38;5;241m=\u001b[39m gain\n",
      "File \u001b[0;32m~/Documents/Universita/Statistical_Method/progetto/decision_tree.py:148\u001b[0m, in \u001b[0;36mDecision_tree._information_gain\u001b[0;34m(self, y, X_column, threshold, continuous)\u001b[0m\n\u001b[1;32m    145\u001b[0m n_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(right_idxs)\n\u001b[1;32m    147\u001b[0m left_purity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_criterion(y\u001b[38;5;241m.\u001b[39mloc[left_idxs])\n\u001b[0;32m--> 148\u001b[0m right_purity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_criterion(\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_idxs\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    150\u001b[0m children_purity \u001b[38;5;241m=\u001b[39m (n_left \u001b[38;5;241m/\u001b[39m n) \u001b[38;5;241m*\u001b[39m left_purity \u001b[38;5;241m+\u001b[39m (n_right \u001b[38;5;241m/\u001b[39m n) \u001b[38;5;241m*\u001b[39m right_purity\n\u001b[1;32m    151\u001b[0m gain \u001b[38;5;241m=\u001b[39m parent_purity \u001b[38;5;241m-\u001b[39m children_purity\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6117\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m   6115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m-> 6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n\u001b[1;32m   6120\u001b[0m     keyarr\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexes/base.py:1159\u001b[0m, in \u001b[0;36mIndex.take\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m   1157\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m-> 1159\u001b[0m     taken \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_na_value\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;66;03m# algos.take passes 'axis' keyword which not all EAs accept\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     taken \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   1165\u001b[0m         indices, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_na_value\n\u001b[1;32m   1166\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/algorithms.py:1319\u001b[0m, in \u001b[0;36mtake\u001b[0;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     result \u001b[38;5;241m=\u001b[39m take_nd(\n\u001b[1;32m   1315\u001b[0m         arr, indices, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m   1316\u001b[0m     )\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;66;03m# NumPy style\u001b[39;00m\n\u001b[0;32m-> 1319\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import decision_tree\n",
    "importlib.reload(decision_tree)  # Ricarica il modulo\n",
    "from sklearn.model_selection import (train_test_split, KFold, StratifiedKFold, KFold,LeaveOneOut)\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "from normalizer import Normalizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "##-------------Load dataset\n",
    "mushroom = fetch_ucirepo(id=848) \n",
    "  \n",
    "attributes_type = mushroom.variables.type\n",
    "# data (as pandas dataframes) \n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets \n",
    "\n",
    "print('-- Dataset loaded --')\n",
    "##-------------\n",
    "param_grid = {\n",
    "    'max_depth': [ 20], \n",
    "    'min_samples_split': [10],\n",
    "    'criterion' : ['gini', 'entropy', 'sqrt_split'],\n",
    "    'min_impurity_decrease' : [0.001]\n",
    "}\n",
    "\n",
    "normalizer = Normalizer(n_bins=4, normalization='minmax')\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "#(max_depth, min_sample, criterion, min_impurity):{accuracy: int, precision: int, recall: int, f1: int}\n",
    "metrics = {}\n",
    "\n",
    "for max_depth in param_grid['max_depth']:\n",
    "    for min_samples_split in param_grid['min_samples_split']:\n",
    "        for criterion in param_grid['criterion']:\n",
    "            for min_impurity_decrease in param_grid['min_impurity_decrease']:\n",
    "                model = decision_tree.Decision_tree(splitting_criteria = criterion, max_depth = max_depth, min_samples_split=min_samples_split, min_impurity_decrease = min_impurity_decrease)\n",
    "            \n",
    "                skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=False)\n",
    "                skf_accuracies=[]\n",
    "                skf_precisions=[]\n",
    "                skf_recalls = []\n",
    "                skf_f1 = []\n",
    "                print(f'-- TRAINING ::: max_dept= {max_depth} | min_samp = {min_samples_split} | criterion = {criterion} | min_impurity = {min_impurity_decrease} ::: --')\n",
    "                count = 1\n",
    "                for train_index, test_index in skf.split(X, y):\n",
    "                    X_train = X.loc[train_index]\n",
    "                    y_train = normalizer._fix_label(y.loc[train_index])\n",
    "                    X_test = X.loc[test_index]\n",
    "                    y_test = normalizer._fix_label(y.loc[test_index])\n",
    "                    training_error = model.fit(X_train,y_train)\n",
    "                    \n",
    "                    print(f'    ({count}/{N_FOLDS}): training error: {t_e}')\n",
    "                    \n",
    "                    y_pred = model.predict(X_test)\n",
    "                    \n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    precision = precision_score(y_test, y_pred)\n",
    "                    recall = recall_score(y_test, y_pred)\n",
    "                    f1 = f1_score(y_test, y_pred)\n",
    "                    \n",
    "                    print(f'     ({count}/{N_FOLDS}): accuracy: {accuracy}')\n",
    "                    \n",
    "                    skf_accuracies.append(accuracy)\n",
    "                    skf_precisions.append(precision)\n",
    "                    skf_recalls.append(recall)\n",
    "                    skf_f1.append(f1)\n",
    "                    \n",
    "                    count+=1\n",
    "                    \n",
    "                metrics[(max_depth, min_samples_split, criterion, min_impurity_decrease)] = {\n",
    "                    'accuracy' : np.mean(skf_accuracies),\n",
    "                    'precision' : np.mean(skf_precisions),\n",
    "                    'recall' : np.mean(skf_recalls),\n",
    "                    'f1': np.mean(skf_f1)\n",
    "                }\n",
    "                \n",
    "\n",
    "                    \n",
    "with open('metrics.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(metrics, f) # serialize the list\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for accuracy: (30, 10, 'entropy', 0.005) with accuracy: 0.577069249058559\n",
      "Best parameters for precision: (30, 10, 'entropy', 0.005) with precision: 0.5305435356425227\n",
      "Best parameters for recall: (10, 10, 'entropy', 0.001) with recall: 0.5901204443856491\n",
      "Best parameters for f1: (10, 10, 'entropy', 0.005) with f1: 0.5255871225929042\n"
     ]
    }
   ],
   "source": [
    "def best_parameter(metrics):\n",
    "    best_accuracy = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_f1 = 0\n",
    "    for combo,values in metrics.items():\n",
    "        if values['accuracy'] > best_accuracy:\n",
    "            best_accuracy = values['accuracy']\n",
    "            best_combo_accuracy = combo\n",
    "        if values['precision'] > best_precision:\n",
    "            best_precision = values['precision']\n",
    "            best_combo_precision = combo\n",
    "        if values['recall'] > best_recall:\n",
    "            best_recall = values['recall']\n",
    "            best_combo_recall = combo\n",
    "        if values['f1'] > best_f1:\n",
    "            best_f1 = values['f1']\n",
    "            best_combo_f1 = combo\n",
    "    return best_combo_accuracy, best_combo_precision, best_combo_recall, best_combo_f1, best_accuracy, best_precision, best_recall, best_f1\n",
    "\n",
    "\n",
    "best_combo_accuracy, best_combo_precision, best_combo_recall, best_combo_f1, best_accuracy, best_precision, best_recall, best_f1 = best_parameter(metrics)\n",
    "#print the best parameters for each metric\n",
    "print(f'Best parameters for accuracy: {best_combo_accuracy} with accuracy: {best_accuracy}')\n",
    "print(f'Best parameters for precision: {best_combo_precision} with precision: {best_precision}')\n",
    "print(f'Best parameters for recall: {best_combo_recall} with recall: {best_recall}')\n",
    "print(f'Best parameters for f1: {best_combo_f1} with f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
